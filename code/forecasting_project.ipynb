{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 1: Advanced Time Series Forecasting with Prophet + Bayesian Optimization\n",
        "# ============================================================\n",
        "\n",
        "!pip install yfinance prophet optuna statsmodels --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "from prophet import Prophet\n",
        "import optuna\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from google.colab import files\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1. DATA ACQUISITION & PREPROCESSING\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "# 1.1 Download at least 3 years of daily data (S&P 500 index)\n",
        "ticker = \"^GSPC\"\n",
        "raw = yf.download(ticker, period=\"10y\", interval=\"1d\", auto_adjust=True)\n",
        "\n",
        "# Explicitly ensure the DataFrame for Prophet has simple 'ds' and 'y' columns.\n",
        "# This prevents potential MultiIndex issues from yfinance output or intermediate steps.\n",
        "df_for_prophet = raw.reset_index()\n",
        "df_for_prophet = df_for_prophet[['Date', 'Close']]\n",
        "df_for_prophet.columns = ['ds', 'y'] # Direct column assignment for clarity and robustness\n",
        "\n",
        "# Sort & enforce daily frequency\n",
        "df_for_prophet = df_for_prophet.sort_values('ds')\n",
        "df_for_prophet.set_index('ds', inplace=True)\n",
        "df_for_prophet = df_for_prophet.asfreq('D')\n",
        "\n",
        "# Interpolate missing values by time\n",
        "df_for_prophet['y'] = df_for_prophet['y'].interpolate(method='time')\n",
        "\n",
        "# Keep last 8 years to keep runtime reasonable (still >3 yrs)\n",
        "if len(df_for_prophet) > 8*365:\n",
        "    df_for_prophet = df_for_prophet.iloc[-8*365:]\n",
        "\n",
        "data = df_for_prophet.reset_index() # The final 'data' DataFrame for Prophet.\n",
        "\n",
        "# Stationarity check with ADF test (on full series)\n",
        "adf_result = adfuller(data['y'])\n",
        "adf_stat = adf_result[0]\n",
        "adf_pvalue = adf_result[1]\n",
        "\n",
        "print(\"ADF Statistic:\", adf_stat)\n",
        "print(\"ADF p-value :\", adf_pvalue)\n",
        "\n",
        "# Save cleaned dataset\n",
        "data.to_csv(\"dataset_prophet.csv\", index=False)\n",
        "\n",
        "# 1.2 Train / Test split (last 60 days as test)\n",
        "TEST_DAYS = 60\n",
        "train_df = data.iloc[:-TEST_DAYS].copy()\n",
        "test_df = data.iloc[-TEST_DAYS:].copy()\n",
        "\n",
        "# Utility: metrics\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "    return rmse, mae, mape\n",
        "\n",
        "short_horizon = 7\n",
        "medium_horizon = 30\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2. BASELINE PROPHET MODEL\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "baseline_model = Prophet()\n",
        "baseline_model.fit(train_df)\n",
        "\n",
        "future_base = baseline_model.make_future_dataframe(periods=TEST_DAYS)\n",
        "forecast_base = baseline_model.predict(future_base)\n",
        "pred_base = forecast_base[['ds', 'yhat']].tail(TEST_DAYS)\n",
        "\n",
        "test_base = test_df.merge(pred_base, on='ds', how='left')\n",
        "\n",
        "rmse_b_short, mae_b_short, mape_b_short = compute_metrics(\n",
        "    test_base['y'].head(short_horizon),\n",
        "    test_base['yhat'].head(short_horizon)\n",
        ")\n",
        "rmse_b_med, mae_b_med, mape_b_med = compute_metrics(\n",
        "    test_base['y'].head(medium_horizon),\n",
        "    test_base['yhat'].head(medium_horizon)\n",
        ")\n",
        "\n",
        "print(\"\\nBaseline Prophet metrics:\")\n",
        "print(\"7-day  -> RMSE={:.4f}, MAE={:.4f}, MAPE={:.2f}%\".format(rmse_b_short, mae_b_short, mape_b_short))\n",
        "print(\"30-day -> RMSE={:.4f}, MAE={:.4f}, MAPE={:.2f}%\".format(rmse_b_med, mae_b_med, mape_b_med))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3. BAYESIAN OPTIMIZATION WITH OPTUNA\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "# Split train into internal train/validation for CV\n",
        "val_split_idx = int(len(train_df) * 0.85)\n",
        "bo_train = train_df.iloc[:val_split_idx].copy()\n",
        "bo_val = train_df.iloc[val_split_idx:].copy()\n",
        "\n",
        "def objective(trial):\n",
        "    seasonality_prior_scale = trial.suggest_float(\"seasonality_prior_scale\", 0.1, 20.0, log=True)\n",
        "    changepoint_prior_scale = trial.suggest_float(\"changepoint_prior_scale\", 0.001, 0.5, log=True)\n",
        "    n_changepoints = trial.suggest_int(\"n_changepoints\", 5, 40)\n",
        "    seasonality_mode = trial.suggest_categorical(\"seasonality_mode\", [\"additive\", \"multiplicative\"])\n",
        "\n",
        "    model = Prophet(\n",
        "        seasonality_prior_scale=seasonality_prior_scale,\n",
        "        changepoint_prior_scale=changepoint_prior_scale,\n",
        "        n_changepoints=n_changepoints,\n",
        "        seasonality_mode=seasonality_mode,\n",
        "    )\n",
        "    model.fit(bo_train)\n",
        "\n",
        "    future = model.make_future_dataframe(periods=len(bo_val))\n",
        "    forecast = model.predict(future)\n",
        "    val_pred = forecast[['ds', 'yhat']].tail(len(bo_val))\n",
        "\n",
        "    merged = bo_val.merge(val_pred, on='ds', how='left')\n",
        "    rmse = sqrt(mean_squared_error(merged['y'], merged['yhat']))\n",
        "    return rmse\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=25, show_progress_bar=False)\n",
        "\n",
        "best_params = study.best_params\n",
        "best_cv_rmse = study.best_value\n",
        "\n",
        "print(\"\\nBest Optuna params:\", best_params)\n",
        "print(\"Best CV RMSE:\", best_cv_rmse)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4. FINAL OPTIMIZED PROPHET MODEL\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "opt_model = Prophet(\n",
        "    seasonality_prior_scale=best_params[\"seasonality_prior_scale\"],\n",
        "    changepoint_prior_scale=best_params[\"changepoint_prior_scale\"],\n",
        "    n_changepoints=best_params[\"n_changepoints\"],\n",
        "    seasonality_mode=best_params[\"seasonality_mode\"],\n",
        ")\n",
        "opt_model.fit(train_df)\n",
        "\n",
        "future_opt = opt_model.make_future_dataframe(periods=TEST_DAYS)\n",
        "forecast_opt = opt_model.predict(future_opt)\n",
        "pred_opt = forecast_opt[['ds', 'yhat']].tail(TEST_DAYS)\n",
        "\n",
        "test_opt = test_df.merge(pred_opt, on='ds', how='left')\n",
        "\n",
        "rmse_o_short, mae_o_short, mape_o_short = compute_metrics(\n",
        "    test_opt['y'].head(short_horizon),\n",
        "    test_opt['yhat'].head(short_horizon)\n",
        ")\n",
        "rmse_o_med, mae_o_med, mape_o_med = compute_metrics(\n",
        "    test_opt['y'].head(medium_horizon),\n",
        "    test_opt['yhat'].head(medium_horizon)\n",
        ")\n",
        "\n",
        "print(\"\\nOptimized Prophet metrics:\")\n",
        "print(\"7-day  -> RMSE={:.4f}, MAE={:.4f}, MAPE={:.2f}%\".format(rmse_o_short, mae_o_short, mape_o_short))\n",
        "print(\"30-day -> RMSE={:.4f}, MAE={:.4f}, MAPE={:.2f}%\".format(rmse_o_med, mae_o_med, mape_o_med))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5. RESIDUAL ANALYSIS (OPTIMIZED MODEL)\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "residuals = test_opt['y'] - test_opt['yhat']\n",
        "\n",
        "# residuals over time\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(test_opt['ds'], residuals, marker='o')\n",
        "plt.axhline(0, color='black', linestyle='--')\n",
        "plt.title(\"Optimized Prophet Residuals (Test Set)\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Residual (y - yhat)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"residuals_time.png\")\n",
        "plt.close()\n",
        "\n",
        "# ACF & PACF plots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
        "plot_acf(residuals, ax=axes[0], lags=30)\n",
        "axes[0].set_title(\"Residuals ACF\")\n",
        "plot_pacf(residuals, ax=axes[1], lags=30, method='ywm')\n",
        "axes[1].set_title(\"Residuals PACF\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"residuals_acf_pacf.png\")\n",
        "plt.close()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6. SAVE ALL OUTPUT FILES\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "# Baseline and optimized predictions\n",
        "baseline_preds = test_base[['ds','y']].copy()\n",
        "baseline_preds['yhat_baseline'] = test_base['yhat']\n",
        "baseline_preds.to_csv(\"baseline_predictions.csv\", index=False)\n",
        "\n",
        "opt_preds = test_opt[['ds','y']].copy()\n",
        "opt_preds['yhat_optimized'] = test_opt['yhat']\n",
        "opt_preds.to_csv(\"optimized_predictions.csv\", index=False)\n",
        "\n",
        "# Metrics table\n",
        "metrics_summary = pd.DataFrame({\n",
        "    \"Model\": [\"Baseline_Prophet\",\"Baseline_Prophet\",\"Optimized_Prophet\",\"Optimized_Prophet\"],\n",
        "    \"Horizon\": [\"7-day\",\"30-day\",\"7-day\",\"30-day\"],\n",
        "    \"RMSE\": [rmse_b_short, rmse_b_med, rmse_o_short, rmse_o_med],\n",
        "    \"MAE\":  [mae_b_short, mae_b_med, mae_o_short, mae_o_med],\n",
        "    \"MAPE\": [mape_b_short, mape_b_med, mape_o_short, mape_o_med],\n",
        "})\n",
        "metrics_summary.to_csv(\"metrics_summary.csv\", index=False)\n",
        "\n",
        "with open(\"metrics_summary.txt\",\"w\") as f:\n",
        "    f.write(\"ADF Statistic: {:.4f}\\nADF p-value: {:.4f}\\n\\n\".format(adf_stat, adf_pvalue))\n",
        "    f.write(metrics_summary.to_string(index=False))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7. DOWNLOAD FILES FROM COLAB\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "for fname in [\n",
        "    \"dataset_prophet.csv\",\n",
        "    \"baseline_predictions.csv\",\n",
        "    \"optimized_predictions.csv\",\n",
        "    \"metrics_summary.csv\",\n",
        "    \"metrics_summary.txt\",\n",
        "    \"residuals_time.png\",\n",
        "    \"residuals_acf_pacf.png\",\n",
        "]:\n",
        "    files.download(fname)\n",
        "\n",
        "print(\"\\nAll main outputs generated & downloaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2fu0gJ1BGgIr",
        "outputId": "ae5c632d-ece2-42da-e568-205dfbcaf79d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/404.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 455, in run\n",
            "    installed = install_given_reqs(\n",
            "                ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/req/__init__.py\", line 70, in install_given_reqs\n",
            "    requirement.install(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/req/req_install.py\", line 851, in install\n",
            "    install_wheel(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/install/wheel.py\", line 726, in install_wheel\n",
            "    _install_wheel(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/install/wheel.py\", line 584, in _install_wheel\n",
            "    file.save()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/install/wheel.py\", line 380, in save\n",
            "    with self._zip_file.open(zipinfo) as f:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/zipfile/__init__.py\", line 1120, in close\n",
            "    self._fileobj.close()\n",
            "  File \"/usr/lib/python3.12/zipfile/__init__.py\", line 835, in close\n",
            "    self._close(fileobj)\n",
            "  File \"/usr/lib/python3.12/zipfile/__init__.py\", line 2084, in _fpclose\n",
            "    def _fpclose(self, fp):\n",
            "\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1586, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
            "    with self:\n",
            "         ^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 865, in __exit__\n",
            "    self._exit_buffer()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 823, in _exit_buffer\n",
            "    self._check_buffer()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 2060, in _check_buffer\n",
            "    self.file.write(text)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'optuna'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-175603919.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myfinance\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprophet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProphet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "VLnyYaToHKFU",
        "outputId": "f88531a7-c262-4bb4-ad38-2d17f92a5820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8a2ba2cb-cad3-4088-aa03-edd58a9bcd96\", \"Prophet_Bayesian_Optimization_Report.pdf\", 6299)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report PDF generated and downloaded: Prophet_Bayesian_Optimization_Report.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bi919HOCHK90"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
